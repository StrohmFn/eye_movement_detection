{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.15\n",
    "session = tf.Session(config=config)\n",
    "tf.keras.backend.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv1D, Flatten, Dense, Activation, MaxPooling1D, UpSampling1D, Cropping1D, ZeroPadding1D, Input, multiply, GlobalMaxPooling1D, Reshape\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import classification_report\n",
    "from random import shuffle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_encoder():\n",
    "    model = Sequential()\n",
    "\n",
    "    #encoder\n",
    "    model.add(ZeroPadding1D((3,2), input_shape = (251, 2), name='Padding'))\n",
    "\n",
    "    model.add(Conv1D(filters=16, kernel_size=(15), activation='relu', padding='same'))\n",
    "    model.add(Conv1D(filters=16, kernel_size=(15), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(strides=2, pool_size=2, padding='same')) \n",
    "\n",
    "    model.add(Conv1D(filters=32, kernel_size=(3), activation='relu', padding='same'))\n",
    "    model.add(Conv1D(filters=32, kernel_size=(3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(strides=2, pool_size=2, padding='same')) \n",
    "\n",
    "    model.add(Conv1D(filters=64, kernel_size=(3), activation='relu', padding='same'))\n",
    "    model.add(Conv1D(filters=64, kernel_size=(3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(strides=2, pool_size=2, padding='same')) \n",
    "\n",
    "    model.add(Conv1D(filters=128, kernel_size=(3), activation='relu', padding='same'))\n",
    "    model.add(Conv1D(filters=128, kernel_size=(3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(strides=2, pool_size=2, padding='same')) \n",
    "\n",
    "    model.add(Conv1D(filters=256, kernel_size=(3), activation='relu', padding='same'))\n",
    "    model.add(Conv1D(filters=256, kernel_size=(3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(strides=2, pool_size=2, padding='same')) \n",
    "\n",
    "\n",
    "    # decoder\n",
    "    model.add(Conv1D(filters=256, kernel_size=(3), activation='relu', padding='same'))\n",
    "    model.add(Conv1D(filters=256, kernel_size=(3), activation='relu', padding='same'))\n",
    "\n",
    "    model.add(UpSampling1D(2))\n",
    "    model.add(Conv1D(filters=128, kernel_size=(3), activation='relu', padding='same'))\n",
    "    model.add(Conv1D(filters=128, kernel_size=(3), activation='relu', padding='same'))\n",
    "\n",
    "    model.add(UpSampling1D(2))\n",
    "    model.add(Conv1D(filters=64, kernel_size=(3), activation='relu', padding='same'))\n",
    "    model.add(Conv1D(filters=64, kernel_size=(3), activation='relu', padding='same'))\n",
    "\n",
    "    model.add(UpSampling1D(2))\n",
    "    model.add(Conv1D(filters=32, kernel_size=(3), activation='relu', padding='same'))\n",
    "    model.add(Conv1D(filters=32, kernel_size=(3), activation='relu', padding='same'))\n",
    "\n",
    "    model.add(UpSampling1D(2))\n",
    "    model.add(Conv1D(filters=16, kernel_size=(3), activation='relu', padding='same'))\n",
    "    model.add(Conv1D(filters=16, kernel_size=(3), activation='relu', padding='same'))\n",
    "\n",
    "    model.add(UpSampling1D(2))\n",
    "    model.add(Conv1D(filters=2, kernel_size=(15), activation='relu', padding='same'))\n",
    "    model.add(Conv1D(filters=2, kernel_size=(15), activation='relu', padding='same'))\n",
    "\n",
    "    model.add(Cropping1D((3,2), name='Cropping'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = auto_encoder()\n",
    "model.summary()\n",
    "model.compile(loss='mean_squared_error', optimizer = Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the data is too large for most systems we are loading 50 files at a time, train on them, load the next 50 and so on. The order in which the files are loaded and the data inside the files are shuffeld each epoch. After each training phase (50 files) we save the current model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'path_to_training_files'\n",
    "files = [f.name for f in os.scandir(data_path)]\n",
    "for e in range(epochs):\n",
    "    \n",
    "    print(\"EPOCH: \" + str(e+1) + \"-\"*100)\n",
    "    \n",
    "    shuffle(files)\n",
    "    \n",
    "    pbar = tqdm(total=len(files))\n",
    "    \n",
    "    #\n",
    "    for i in range(0, len(files), 50):\n",
    "        pbar.update(1)\n",
    "        x_train = np.load(data_path + \"/\" + files[i])\n",
    "        j = 1\n",
    "        while j+i < len(files) and j<50:\n",
    "            pbar.update(1)\n",
    "            x_train = np.concatenate((x_train, np.load(data_path + \"/\" + files[i+j])))\n",
    "            j += 1\n",
    "            \n",
    "        model.fit(x_train, x_train, batch_size=batch_size, verbose=1, shuffle=True)\n",
    "        model.save_weights('latest_autoencoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
